{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e61b55c39330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "probas = [0.2, 0.8]\n",
    "\n",
    "np.sum(probas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # links to the left and right child nodes\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        # derived from splitting criteria\n",
    "        self.column = None\n",
    "        self.threshold = None\n",
    "        \n",
    "        # probability for object inside the Node to belong for each of the given classes\n",
    "        self.probas = None\n",
    "        # depth of the given node\n",
    "        self.depth = None\n",
    "        \n",
    "        # if it is the root Node or not\n",
    "        self.is_terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth = 3, min_samples_leaf = 1, min_samples_split = 2):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "        self.classes = None\n",
    "        \n",
    "        # Decision tree itself\n",
    "        self.Tree = None\n",
    "    \n",
    "    def nodeProbas(self, y):\n",
    "        '''\n",
    "        Calculates probability of class in a given node\n",
    "        '''\n",
    "        \n",
    "        probas = []\n",
    "        \n",
    "        # for each unique label calculate the probability for it\n",
    "        for one_class in self.classes:\n",
    "            proba = y[y == one_class].shape[0] / y.shape[0]\n",
    "            probas.append(proba)\n",
    "        return np.asarray(probas)\n",
    "\n",
    "    def gini(self, probas):\n",
    "        '''\n",
    "        Calculates gini criterion\n",
    "        '''\n",
    "        \n",
    "        return 1 - np.sum(probas**2)\n",
    "    \n",
    "    def getImpurity_faster(self, target, class_list):\n",
    "        # 기본적으로 np.where 을 하면 tuple 형태이다. ( array([idx1, idx2 ,,, ]), ) \n",
    "        probas = []\n",
    "        for one_class in class_list:\n",
    "            prob = np.where(target == one_class)[0].size / target.shape[0]\n",
    "            probas.append(prob)\n",
    "    \n",
    "        # gini 계수를 구한다. \n",
    "        return 1-np.sum(np.asarray(probas)**2)\n",
    "    \n",
    "    def calcBestSplit(self, X, y):\n",
    "        '''\n",
    "        X : np.asarray 를 통해서 이미 numpy array 형태로 변환된 것이다. \n",
    "        Calculates the best possible split for the concrete node of the tree\n",
    "        '''\n",
    "        class_list = [0,1,2]\n",
    "        bestSplitCol = None\n",
    "        bestThresh = None\n",
    "        bestInfoGain = -999\n",
    "        \n",
    "        # 나누기 전 현재의 데이터 분포에서 impurity 를 계산한다. \n",
    "        impurityBefore = self.getImpurity_faster(y, class_list)\n",
    "        \n",
    "        # X는 2차원의 table 데이터 이므로, (행 수, 열 수) 의 shape을 갖는다. \n",
    "        # 따라서, 모든 variable 들에 대해서 info gain을 계산해야 하므로 loop 돌린다. \n",
    "        \n",
    "        for col in range(X.shape[1]):\n",
    "            \n",
    "            # X 가 이미 np.array 아래와같이 indexing이 가능. .iloc이 아님. \n",
    "            x_col = X[:, col]  # 행은 전부다, 열은 col으로 지정한 열만. \n",
    "            \n",
    "            # 각각의 모든 value 들을 기준로 나눈다. \n",
    "            for x_i in x_col:\n",
    "                threshold = x_i\n",
    "                y_right = np.where(y  > threshold)[0]\n",
    "                y_left = np.where(y <=threshold)[0]\n",
    "                \n",
    "                if y_right.shape[0] == 0 or y_left.shape[0] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # calculate impurity for the right and left nodes\n",
    "                impurityRight = self.getImpurity_faster(y_right, class_list)\n",
    "                impurityLeft = self.getImpurity_faster(y_left, class_list)\n",
    "                \n",
    "                # calculate information gain\n",
    "                infoGain = impurityBefore\n",
    "                infoGain -= (impurityLeft * y_left.shape[0] / y.shape[0]) + (impurityRight * y_right.shape[0] / y.shape[0])\n",
    "                \n",
    "                # is this infoGain better then all other?\n",
    "                if infoGain > bestInfoGain:\n",
    "                    bestSplitCol = col\n",
    "                    bestThresh = threshold\n",
    "                    bestInfoGain = infoGain\n",
    "                    \n",
    "        \n",
    "        # if we still didn't find the split\n",
    "        if bestInfoGain == -999:\n",
    "            return None, None, None, None, None, None\n",
    "        \n",
    "        # making the best split\n",
    "        \n",
    "        x_col = X[:, bestSplitCol]\n",
    "        x_left, x_right = X[x_col <= bestThresh, :], X[x_col > bestThresh, :]\n",
    "        y_left, y_right = y[x_col <= bestThresh], y[x_col > bestThresh]\n",
    "        \n",
    "        return bestSplitCol, bestThresh, x_left, y_left, x_right, y_right\n",
    "                \n",
    "                \n",
    "    \n",
    "    def buildDT(self, X, y, node):\n",
    "        '''\n",
    "        Recursively builds decision tree from the top to bottom\n",
    "        '''\n",
    "        \n",
    "        # checking for the terminal conditions\n",
    "        \n",
    "        if node.depth >= self.max_depth:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        if X.shape[0] < self.min_samples_split:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        # calculating current split\n",
    "        splitCol, thresh, x_left, y_left, x_right, y_right = self.calcBestSplit(X, y)\n",
    "        \n",
    "        if splitCol is None:\n",
    "            node.is_terminal = True\n",
    "            \n",
    "        if x_left.shape[0] < self.min_samples_leaf or x_right.shape[0] < self.min_samples_leaf:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        node.column = splitCol\n",
    "        node.threshold = thresh\n",
    "        \n",
    "        # creating left and right child nodes\n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.probas = self.nodeProbas(y_left)\n",
    "        \n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.probas = self.nodeProbas(y_right)\n",
    "        \n",
    "        # splitting recursevely\n",
    "        self.buildDT(x_right, y_right, node.right)\n",
    "        self.buildDT(x_left, y_left, node.left)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        X : y만 빠진 column들이 모두 존재하는 pandas dataframe.\n",
    "        y : y 하나만 존재하는 pandas dataframe\n",
    "        '''\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X = np.asarray(X)\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        # root node creation\n",
    "        self.Tree = Node()\n",
    "        self.Tree.depth = 1\n",
    "        \n",
    "        # 현재 root node, 즉 모든 데이터에 대해서 probas 를 계산한다. \n",
    "        self.Tree.probas = self.nodeProbas(y)\n",
    "        \n",
    "        # 그렇게 root node 를 손수 만들어준 다음, 그 root node 를 기준으로 tree를 만든다. \n",
    "        self.buildDT(X, y, self.Tree)\n",
    "    \n",
    "    def predictSample(self, x, node):\n",
    "        '''\n",
    "        Passes one object through decision tree and return the probability of it to belong to each class\n",
    "        '''\n",
    "       \n",
    "    \n",
    "        # if we have reached the terminal node of the tree\n",
    "        if node.is_terminal:\n",
    "            return node.probas\n",
    "        \n",
    "        if x[node.column] > node.threshold:\n",
    "            probas = self.predictSample(x, node.right)\n",
    "        else:\n",
    "            probas = self.predictSample(x, node.left)\n",
    "            \n",
    "        return probas\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Returns the labels for each X\n",
    "        '''\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X = np.asarray(X)\n",
    "            \n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred = np.argmax(self.predictSample(x, self.Tree))\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # links to the left and right child nodes\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        # derived from splitting criteria\n",
    "        self.column = None\n",
    "        self.threshold = None\n",
    "        \n",
    "        # probability for object inside the Node to belong for each of the given classes\n",
    "        self.probas = None\n",
    "        # depth of the given node\n",
    "        self.depth = None\n",
    "        \n",
    "        # if it is the root Node or not\n",
    "        self.is_terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_iris()\n",
    "X, y, column_names = data['data'], data['target'], data['feature_names']\n",
    "X = pd.DataFrame(X, columns = column_names)\n",
    "X['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.drop(columns = 'target'), X['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap(df, nboot):\n",
    "    idx = np.random.randint(df.shape[0], size = (nboot, df.shape[0]))\n",
    "    idx_flat = np.ravel(idx)\n",
    "    \n",
    "    return df.iloc[idx_flat, :]\n",
    "data = load_iris()\n",
    "X, y, column_names = data['data'], data['target'], data['feature_names']\n",
    "X = pd.DataFrame(X, columns = column_names)\n",
    "X['target'] = y\n",
    "\n",
    "bootstappedDF = bootstrap(X, 100000)\n",
    "bigX, bigy = bootstappedDF.drop(columns = 'target'), bootstappedDF['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(bigX,bigy, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11250000, 4)\n",
      "(3750000, 4)\n",
      "(11250000,)\n",
      "(3750000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 135 ms, total: 14.3 s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=8, min_samples_leaf=2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model = DecisionTreeClassifier(max_depth = 8, min_samples_leaf=2, min_samples_split=2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for self built model 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_val)\n",
    "print(f'Accuracy for self built model {accuracy_score(y_val, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 136 ms, total: 14.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf = dt_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_prediction = dt_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1248512,       0,       0],\n",
       "       [      0, 1250613,       0],\n",
       "       [      0,       0, 1250875]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, dt_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
